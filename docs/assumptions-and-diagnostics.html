<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 20 Assumptions and diagnostics | Introductory Biostatistics with R</title>
  <meta name="description" content="This is the Introductory Biostatisics with R book provided by the School of Biosciences, University of Sheffield." />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 20 Assumptions and diagnostics | Introductory Biostatistics with R" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is the Introductory Biostatisics with R book provided by the School of Biosciences, University of Sheffield." />
  <meta name="github-repo" content="tuos-bio-data-skills/intro-stats-book" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 20 Assumptions and diagnostics | Introductory Biostatistics with R" />
  
  <meta name="twitter:description" content="This is the Introductory Biostatisics with R book provided by the School of Biosciences, University of Sheffield." />
  

<meta name="author" content="Dylan Z. Childs, Bethan J. Hindle and Philip H. Warren" />


<meta name="date" content="2021-09-22" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="anova-for-randomised-block-designs.html"/>
<link rel="next" href="regression-diagnostics-in-r.html"/>
<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Introductory Biostatistics with R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Course information and overview</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#why-do-a-data-analysis-course"><i class="fa fa-check"></i>Why do a data analysis course?</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#programming-prerequisites"><i class="fa fa-check"></i>Programming prerequisites</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#r-and-rstudio"><i class="fa fa-check"></i>R and RStudio</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#using-packages"><i class="fa fa-check"></i>Using packages</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#working-with-data"><i class="fa fa-check"></i>Working with data</a></li>
<li><a href="index.html#data-wrangling-with-dplyr">Data wrangling with <strong>dplyr</strong></a></li>
<li><a href="index.html#plotting-with-ggplot2">Plotting with <strong>ggplot2</strong></a></li>
</ul></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#how-the-book-is-formatted"><i class="fa fa-check"></i>How the book is formatted</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#text-instructions-and-explanations"><i class="fa fa-check"></i>Text, instructions, and explanations</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#r-code-and-output"><i class="fa fa-check"></i>R code and output</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>I Collecting and Using Data</b></span></li>
<li class="chapter" data-level="1" data-path="scientific-process.html"><a href="scientific-process.html"><i class="fa fa-check"></i><b>1</b> The scientific process</a>
<ul>
<li class="chapter" data-level="1.1" data-path="scientific-process.html"><a href="scientific-process.html#stages-scientific-process"><i class="fa fa-check"></i><b>1.1</b> Stages in the scientific process</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="scientific-process.html"><a href="scientific-process.html#stages-observations"><i class="fa fa-check"></i><b>1.1.1</b> Observations</a></li>
<li class="chapter" data-level="1.1.2" data-path="scientific-process.html"><a href="scientific-process.html#stages-questions"><i class="fa fa-check"></i><b>1.1.2</b> Questions</a></li>
<li class="chapter" data-level="1.1.3" data-path="scientific-process.html"><a href="scientific-process.html#stages-hypotheses"><i class="fa fa-check"></i><b>1.1.3</b> Hypotheses</a></li>
<li class="chapter" data-level="1.1.4" data-path="scientific-process.html"><a href="scientific-process.html#stages-predictions"><i class="fa fa-check"></i><b>1.1.4</b> Predictions</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="scientific-process.html"><a href="scientific-process.html#an-example"><i class="fa fa-check"></i><b>1.2</b> An example</a></li>
<li class="chapter" data-level="1.3" data-path="scientific-process.html"><a href="scientific-process.html#hypothesis-testing"><i class="fa fa-check"></i><b>1.3</b> Hypothesis testing</a></li>
<li class="chapter" data-level="1.4" data-path="scientific-process.html"><a href="scientific-process.html#are-we-sure"><i class="fa fa-check"></i><b>1.4</b> Don’t we ever know anything for sure?</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="data-variables.html"><a href="data-variables.html"><i class="fa fa-check"></i><b>2</b> Data and variables</a>
<ul>
<li class="chapter" data-level="2.1" data-path="data-variables.html"><a href="data-variables.html#observations-on-material-and-obvious-things"><i class="fa fa-check"></i><b>2.1</b> “Observations on material and obvious things”</a></li>
<li class="chapter" data-level="2.2" data-path="data-variables.html"><a href="data-variables.html#var-types"><i class="fa fa-check"></i><b>2.2</b> Revision: Types of variable</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="data-variables.html"><a href="data-variables.html#nominal-categorical-variables"><i class="fa fa-check"></i><b>2.2.1</b> Nominal (categorical) variables</a></li>
<li class="chapter" data-level="2.2.2" data-path="data-variables.html"><a href="data-variables.html#ordinal-categorical-data"><i class="fa fa-check"></i><b>2.2.2</b> Ordinal (categorical) data</a></li>
<li class="chapter" data-level="2.2.3" data-path="data-variables.html"><a href="data-variables.html#ratio-scale-numeric-variables"><i class="fa fa-check"></i><b>2.2.3</b> Ratio scale (numeric) variables</a></li>
<li class="chapter" data-level="2.2.4" data-path="data-variables.html"><a href="data-variables.html#interval-scale-numeric-variables"><i class="fa fa-check"></i><b>2.2.4</b> Interval scale (numeric) variables</a></li>
<li class="chapter" data-level="2.2.5" data-path="data-variables.html"><a href="data-variables.html#why-does-the-distinction-matter"><i class="fa fa-check"></i><b>2.2.5</b> Why does the distinction matter?</a></li>
<li class="chapter" data-level="2.2.6" data-path="data-variables.html"><a href="data-variables.html#which-is-best"><i class="fa fa-check"></i><b>2.2.6</b> Which is best?</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="data-variables.html"><a href="data-variables.html#accuracy-precision"><i class="fa fa-check"></i><b>2.3</b> Accuracy and precision</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="data-variables.html"><a href="data-variables.html#what-do-they-mean"><i class="fa fa-check"></i><b>2.3.1</b> What do they mean?</a></li>
<li class="chapter" data-level="2.3.2" data-path="data-variables.html"><a href="data-variables.html#implied-precision-significant-figures"><i class="fa fa-check"></i><b>2.3.2</b> Implied precision – significant figures</a></li>
<li class="chapter" data-level="2.3.3" data-path="data-variables.html"><a href="data-variables.html#how-precise-should-measurements-be"><i class="fa fa-check"></i><b>2.3.3</b> How precise should measurements be?</a></li>
<li class="chapter" data-level="2.3.4" data-path="data-variables.html"><a href="data-variables.html#error-bias-and-prejudice"><i class="fa fa-check"></i><b>2.3.4</b> Error, bias and prejudice</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="learning-from-data.html"><a href="learning-from-data.html"><i class="fa fa-check"></i><b>3</b> Learning from data</a>
<ul>
<li class="chapter" data-level="3.1" data-path="learning-from-data.html"><a href="learning-from-data.html#populations"><i class="fa fa-check"></i><b>3.1</b> Populations</a></li>
<li class="chapter" data-level="3.2" data-path="learning-from-data.html"><a href="learning-from-data.html#learning-about-populations"><i class="fa fa-check"></i><b>3.2</b> Learning about populations</a></li>
<li class="chapter" data-level="3.3" data-path="learning-from-data.html"><a href="learning-from-data.html#morph-example"><i class="fa fa-check"></i><b>3.3</b> A simple example</a></li>
<li class="chapter" data-level="3.4" data-path="learning-from-data.html"><a href="learning-from-data.html#now-what"><i class="fa fa-check"></i><b>3.4</b> Now what?</a></li>
</ul></li>
<li class="part"><span><b>II Statistical Concepts</b></span></li>
<li class="chapter" data-level="4" data-path="sampling-error.html"><a href="sampling-error.html"><i class="fa fa-check"></i><b>4</b> Sampling error</a>
<ul>
<li class="chapter" data-level="4.1" data-path="sampling-error.html"><a href="sampling-error.html#sampling-error-1"><i class="fa fa-check"></i><b>4.1</b> Sampling error</a></li>
<li class="chapter" data-level="4.2" data-path="sampling-error.html"><a href="sampling-error.html#sampling-distributions"><i class="fa fa-check"></i><b>4.2</b> Sampling distributions</a></li>
<li class="chapter" data-level="4.3" data-path="sampling-error.html"><a href="sampling-error.html#the-effect-of-sample-size"><i class="fa fa-check"></i><b>4.3</b> The effect of sample size</a></li>
<li class="chapter" data-level="4.4" data-path="sampling-error.html"><a href="sampling-error.html#the-standard-error"><i class="fa fa-check"></i><b>4.4</b> The standard error</a></li>
<li class="chapter" data-level="4.5" data-path="sampling-error.html"><a href="sampling-error.html#what-is-the-point-of-all-this"><i class="fa fa-check"></i><b>4.5</b> What is the point of all this?</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="statistical-significance-and-p-values.html"><a href="statistical-significance-and-p-values.html"><i class="fa fa-check"></i><b>5</b> Statistical significance and <em>p</em>-values</a>
<ul>
<li class="chapter" data-level="5.1" data-path="statistical-significance-and-p-values.html"><a href="statistical-significance-and-p-values.html#bootstrap"><i class="fa fa-check"></i><b>5.1</b> Estimating a sampling distribution</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="statistical-significance-and-p-values.html"><a href="statistical-significance-and-p-values.html#bootstrap-overview"><i class="fa fa-check"></i><b>5.1.1</b> Overview of bootstrapping</a></li>
<li class="chapter" data-level="5.1.2" data-path="statistical-significance-and-p-values.html"><a href="statistical-significance-and-p-values.html#doing-it-for-real"><i class="fa fa-check"></i><b>5.1.2</b> Doing it for real</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="statistical-significance-and-p-values.html"><a href="statistical-significance-and-p-values.html#statistical-significance"><i class="fa fa-check"></i><b>5.2</b> Statistical significance</a>
<ul>
<li class="chapter" data-level="" data-path="statistical-significance-and-p-values.html"><a href="statistical-significance-and-p-values.html#carrying-out-the-assessment"><i class="fa fa-check"></i>Carrying out the assessment</a></li>
<li class="chapter" data-level="" data-path="statistical-significance-and-p-values.html"><a href="statistical-significance-and-p-values.html#interpreting-the-p-value"><i class="fa fa-check"></i>Interpreting the p-value</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="statistical-significance-and-p-values.html"><a href="statistical-significance-and-p-values.html#concluding-remarks"><i class="fa fa-check"></i><b>5.3</b> Concluding remarks</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="statistical-comparisons.html"><a href="statistical-comparisons.html"><i class="fa fa-check"></i><b>6</b> Statistical comparisons</a>
<ul>
<li class="chapter" data-level="6.1" data-path="statistical-comparisons.html"><a href="statistical-comparisons.html#making-comparisons"><i class="fa fa-check"></i><b>6.1</b> Making comparisons</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="statistical-comparisons.html"><a href="statistical-comparisons.html#morph-weights-eg"><i class="fa fa-check"></i><b>6.1.1</b> A new example</a></li>
<li class="chapter" data-level="6.1.2" data-path="statistical-comparisons.html"><a href="statistical-comparisons.html#examine-the-data"><i class="fa fa-check"></i><b>6.1.2</b> Examine the data</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="statistical-comparisons.html"><a href="statistical-comparisons.html#constructing-a-test"><i class="fa fa-check"></i><b>6.2</b> Constructing a test</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="statistical-comparisons.html"><a href="statistical-comparisons.html#permutation-tests"><i class="fa fa-check"></i><b>6.2.1</b> Permutation tests</a></li>
<li class="chapter" data-level="6.2.2" data-path="statistical-comparisons.html"><a href="statistical-comparisons.html#carrying-out-a-permutation-test"><i class="fa fa-check"></i><b>6.2.2</b> Carrying out a permutation test</a></li>
<li><a href="statistical-comparisons.html#calculating-the-p-value">Calculating the <em>p</em>-value</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="statistical-comparisons.html"><a href="statistical-comparisons.html#what-have-we-learned"><i class="fa fa-check"></i><b>6.3</b> What have we learned?</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="hypotheses-and-p-values.html"><a href="hypotheses-and-p-values.html"><i class="fa fa-check"></i><b>7</b> Hypotheses and <em>p</em>-values</a>
<ul>
<li class="chapter" data-level="7.1" data-path="hypotheses-and-p-values.html"><a href="hypotheses-and-p-values.html#a-few-words-about-the-null-hypothesis"><i class="fa fa-check"></i><b>7.1</b> A few words about the null hypothesis</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="hypotheses-and-p-values.html"><a href="hypotheses-and-p-values.html#hypotheses-and-null-hypotheses"><i class="fa fa-check"></i><b>7.1.1</b> Hypotheses and null hypotheses</a></li>
<li class="chapter" data-level="7.1.2" data-path="hypotheses-and-p-values.html"><a href="hypotheses-and-p-values.html#report-the-null-hypothesis"><i class="fa fa-check"></i><b>7.1.2</b> Report the null hypothesis?</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="hypotheses-and-p-values.html"><a href="hypotheses-and-p-values.html#interpreting-and-reporting-p-values"><i class="fa fa-check"></i><b>7.2</b> Interpreting and reporting <em>p</em>-values</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="hypotheses-and-p-values.html"><a href="hypotheses-and-p-values.html#careful-with-those-p-values"><i class="fa fa-check"></i><b>7.2.1</b> Careful with those <em>p</em>-values</a></li>
<li class="chapter" data-level="7.2.2" data-path="hypotheses-and-p-values.html"><a href="hypotheses-and-p-values.html#presenting-p-values"><i class="fa fa-check"></i><b>7.2.2</b> Presenting <em>p</em>-values</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="hypotheses-and-p-values.html"><a href="hypotheses-and-p-values.html#biological-vs.-statistical-significance"><i class="fa fa-check"></i><b>7.3</b> Biological vs. statistical significance</a></li>
</ul></li>
<li class="part"><span><b>III Simple Statistics</b></span></li>
<li class="chapter" data-level="8" data-path="parametric-statistics.html"><a href="parametric-statistics.html"><i class="fa fa-check"></i><b>8</b> Parametric statistics</a>
<ul>
<li class="chapter" data-level="8.1" data-path="parametric-statistics.html"><a href="parametric-statistics.html#introduction"><i class="fa fa-check"></i><b>8.1</b> Introduction</a></li>
<li class="chapter" data-level="8.2" data-path="parametric-statistics.html"><a href="parametric-statistics.html#math-models"><i class="fa fa-check"></i><b>8.2</b> Mathematical models</a></li>
<li class="chapter" data-level="8.3" data-path="parametric-statistics.html"><a href="parametric-statistics.html#parametric-stats"><i class="fa fa-check"></i><b>8.3</b> The normal distribution</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="parametric-statistics.html"><a href="parametric-statistics.html#standard-error-of-the-mean"><i class="fa fa-check"></i><b>8.3.1</b> Standard error of the mean</a></li>
<li class="chapter" data-level="8.3.2" data-path="parametric-statistics.html"><a href="parametric-statistics.html#the-t-distribution"><i class="fa fa-check"></i><b>8.3.2</b> The <em>t</em> distribution</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="one-sample-t-tests.html"><a href="one-sample-t-tests.html"><i class="fa fa-check"></i><b>9</b> One sample <em>t</em>-tests</a>
<ul>
<li class="chapter" data-level="9.1" data-path="one-sample-t-tests.html"><a href="one-sample-t-tests.html#when-do-we-use-a-one-sample-t-test"><i class="fa fa-check"></i><b>9.1</b> When do we use a one-sample <em>t</em>-test?</a></li>
<li class="chapter" data-level="9.2" data-path="one-sample-t-tests.html"><a href="one-sample-t-tests.html#how-does-the-one-sample-t-test-work"><i class="fa fa-check"></i><b>9.2</b> How does the one-sample <em>t</em>-test work?</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="one-sample-t-tests.html"><a href="one-sample-t-tests.html#assumptions-of-the-one-sample-t-test"><i class="fa fa-check"></i><b>9.2.1</b> Assumptions of the one-sample <em>t</em>-test</a></li>
<li class="chapter" data-level="9.2.2" data-path="one-sample-t-tests.html"><a href="one-sample-t-tests.html#evaluating-the-assumptions"><i class="fa fa-check"></i><b>9.2.2</b> Evaluating the assumptions</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="one-sample-t-tests.html"><a href="one-sample-t-tests.html#carrying-out-a-one-sample-t-test-in-r"><i class="fa fa-check"></i><b>9.3</b> Carrying out a one-sample <em>t</em>-test in R</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="one-sample-t-tests.html"><a href="one-sample-t-tests.html#visualising-the-data-and-checking-the-assumptions"><i class="fa fa-check"></i><b>9.3.1</b> Visualising the data and checking the assumptions</a></li>
<li class="chapter" data-level="9.3.2" data-path="one-sample-t-tests.html"><a href="one-sample-t-tests.html#carrying-out-the-test"><i class="fa fa-check"></i><b>9.3.2</b> Carrying out the test</a></li>
<li class="chapter" data-level="9.3.3" data-path="one-sample-t-tests.html"><a href="one-sample-t-tests.html#summarising-the-result"><i class="fa fa-check"></i><b>9.3.3</b> Summarising the result</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="two-sample-t-test.html"><a href="two-sample-t-test.html"><i class="fa fa-check"></i><b>10</b> Two-sample <em>t</em>-test</a>
<ul>
<li class="chapter" data-level="10.1" data-path="two-sample-t-test.html"><a href="two-sample-t-test.html#when-do-we-use-a-two-sample-t-test"><i class="fa fa-check"></i><b>10.1</b> When do we use a two-sample <em>t</em>-test?</a></li>
<li class="chapter" data-level="10.2" data-path="two-sample-t-test.html"><a href="two-sample-t-test.html#how-does-the-two-sample-t-test-work"><i class="fa fa-check"></i><b>10.2</b> How does the two-sample <em>t</em>-test work?</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="two-sample-t-test.html"><a href="two-sample-t-test.html#assumptions-of-the-two-sample-t-test"><i class="fa fa-check"></i><b>10.2.1</b> Assumptions of the two-sample <em>t</em>-test</a></li>
<li class="chapter" data-level="10.2.2" data-path="two-sample-t-test.html"><a href="two-sample-t-test.html#evaluating-the-assumptions-1"><i class="fa fa-check"></i><b>10.2.2</b> Evaluating the assumptions</a></li>
<li class="chapter" data-level="10.2.3" data-path="two-sample-t-test.html"><a href="two-sample-t-test.html#what-about-the-equal-variance-assumption"><i class="fa fa-check"></i><b>10.2.3</b> What about the <em>equal variance</em> assumption?</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="two-sample-t-test.html"><a href="two-sample-t-test.html#carrying-out-a-two-sample-t-test-in-r"><i class="fa fa-check"></i><b>10.3</b> Carrying out a two-sample <em>t</em>-test in R</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="two-sample-t-test.html"><a href="two-sample-t-test.html#visualising-the-data-and-checking-the-assumptions-1"><i class="fa fa-check"></i><b>10.3.1</b> Visualising the data and checking the assumptions</a></li>
<li class="chapter" data-level="10.3.2" data-path="two-sample-t-test.html"><a href="two-sample-t-test.html#carrying-out-the-test-1"><i class="fa fa-check"></i><b>10.3.2</b> Carrying out the test</a></li>
<li class="chapter" data-level="10.3.3" data-path="two-sample-t-test.html"><a href="two-sample-t-test.html#summarising-the-result-1"><i class="fa fa-check"></i><b>10.3.3</b> Summarising the result</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>IV Correlation and Regression</b></span></li>
<li class="chapter" data-level="11" data-path="correlation-tests.html"><a href="correlation-tests.html"><i class="fa fa-check"></i><b>11</b> Correlation tests</a>
<ul>
<li class="chapter" data-level="11.1" data-path="correlation-tests.html"><a href="correlation-tests.html#pearsons-product-moment-correlation"><i class="fa fa-check"></i><b>11.1</b> Pearson’s product-moment correlation</a>
<ul>
<li class="chapter" data-level="11.1.1" data-path="correlation-tests.html"><a href="correlation-tests.html#pearsons-correlation-test"><i class="fa fa-check"></i><b>11.1.1</b> Pearson’s correlation test</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="correlation-tests.html"><a href="correlation-tests.html#pearsons-product-moment-correlation-coefficient-in-r"><i class="fa fa-check"></i><b>11.2</b> Pearson’s product-moment correlation coefficient in R</a>
<ul>
<li class="chapter" data-level="11.2.1" data-path="correlation-tests.html"><a href="correlation-tests.html#visualising-the-data-and-checking-the-assumptions-2"><i class="fa fa-check"></i><b>11.2.1</b> Visualising the data and checking the assumptions</a></li>
<li class="chapter" data-level="11.2.2" data-path="correlation-tests.html"><a href="correlation-tests.html#doing-the-test"><i class="fa fa-check"></i><b>11.2.2</b> Doing the test</a></li>
<li class="chapter" data-level="11.2.3" data-path="correlation-tests.html"><a href="correlation-tests.html#reporting-the-result"><i class="fa fa-check"></i><b>11.2.3</b> Reporting the result</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="correlation-tests.html"><a href="correlation-tests.html#next-steps"><i class="fa fa-check"></i><b>11.3</b> Next steps</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="relationships-and-regression.html"><a href="relationships-and-regression.html"><i class="fa fa-check"></i><b>12</b> Relationships and regression</a>
<ul>
<li class="chapter" data-level="12.1" data-path="relationships-and-regression.html"><a href="relationships-and-regression.html#introduction-1"><i class="fa fa-check"></i><b>12.1</b> Introduction</a></li>
<li class="chapter" data-level="12.2" data-path="relationships-and-regression.html"><a href="relationships-and-regression.html#what-does-linear-regression-do"><i class="fa fa-check"></i><b>12.2</b> What does linear regression do?</a></li>
<li class="chapter" data-level="12.3" data-path="relationships-and-regression.html"><a href="relationships-and-regression.html#how-does-simple-linear-regression-work"><i class="fa fa-check"></i><b>12.3</b> How does simple linear regression work?</a>
<ul>
<li class="chapter" data-level="12.3.1" data-path="relationships-and-regression.html"><a href="relationships-and-regression.html#finding-the-best-fit-line"><i class="fa fa-check"></i><b>12.3.1</b> Finding the best fit line</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="relationships-and-regression.html"><a href="relationships-and-regression.html#what-do-you-get-out-of-a-regression"><i class="fa fa-check"></i><b>12.4</b> What do you get out of a regression?</a>
<ul>
<li class="chapter" data-level="12.4.1" data-path="relationships-and-regression.html"><a href="relationships-and-regression.html#interpreting-a-regression"><i class="fa fa-check"></i><b>12.4.1</b> Interpreting a regression</a></li>
<li class="chapter" data-level="12.4.2" data-path="relationships-and-regression.html"><a href="relationships-and-regression.html#evaluating-hypotheses-inference"><i class="fa fa-check"></i><b>12.4.2</b> Evaluating hypotheses (‘inference’)</a></li>
</ul></li>
<li class="chapter" data-level="12.5" data-path="relationships-and-regression.html"><a href="relationships-and-regression.html#correlation-or-regression"><i class="fa fa-check"></i><b>12.5</b> Correlation or regression?</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="regression-in-R.html"><a href="regression-in-R.html"><i class="fa fa-check"></i><b>13</b> Simple regression in R</a>
<ul>
<li class="chapter" data-level="13.1" data-path="regression-in-R.html"><a href="regression-in-R.html#introduction-2"><i class="fa fa-check"></i><b>13.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="13.1.1" data-path="regression-in-R.html"><a href="regression-in-R.html#first-steps"><i class="fa fa-check"></i><b>13.1.1</b> First steps</a></li>
<li class="chapter" data-level="13.1.2" data-path="regression-in-R.html"><a href="regression-in-R.html#visualising-the-data"><i class="fa fa-check"></i><b>13.1.2</b> Visualising the data</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="regression-in-R.html"><a href="regression-in-R.html#model-fitting-and-significance-tests"><i class="fa fa-check"></i><b>13.2</b> Model fitting and significance tests</a>
<ul>
<li class="chapter" data-level="13.2.1" data-path="regression-in-R.html"><a href="regression-in-R.html#extracting-a-little-more-information"><i class="fa fa-check"></i><b>13.2.1</b> Extracting a little more information</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="regression-in-R.html"><a href="regression-in-R.html#present-results"><i class="fa fa-check"></i><b>13.3</b> Presenting results</a>
<ul>
<li class="chapter" data-level="13.3.1" data-path="regression-in-R.html"><a href="regression-in-R.html#plotting-the-fitted-line-and-the-data"><i class="fa fa-check"></i><b>13.3.1</b> Plotting the fitted line and the data</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="regression-in-R.html"><a href="regression-in-R.html#regression-causation"><i class="fa fa-check"></i><b>13.4</b> What about causation?</a></li>
</ul></li>
<li class="part"><span><b>V One-way ANOVA</b></span></li>
<li class="chapter" data-level="14" data-path="introduction-to-one-way-anova.html"><a href="introduction-to-one-way-anova.html"><i class="fa fa-check"></i><b>14</b> Introduction to one-way ANOVA</a>
<ul>
<li class="chapter" data-level="14.1" data-path="introduction-to-one-way-anova.html"><a href="introduction-to-one-way-anova.html#intro"><i class="fa fa-check"></i><b>14.1</b> Introduction</a></li>
<li class="chapter" data-level="14.2" data-path="introduction-to-one-way-anova.html"><a href="introduction-to-one-way-anova.html#why-do-we-need-anova-models"><i class="fa fa-check"></i><b>14.2</b> Why do we need ANOVA models?</a></li>
<li class="chapter" data-level="14.3" data-path="introduction-to-one-way-anova.html"><a href="introduction-to-one-way-anova.html#how-does-anova-work"><i class="fa fa-check"></i><b>14.3</b> How does ANOVA work?</a>
<ul>
<li class="chapter" data-level="14.3.1" data-path="introduction-to-one-way-anova.html"><a href="introduction-to-one-way-anova.html#degrees-of-freedom"><i class="fa fa-check"></i><b>14.3.1</b> Degrees of freedom</a></li>
<li class="chapter" data-level="14.3.2" data-path="introduction-to-one-way-anova.html"><a href="introduction-to-one-way-anova.html#mean-squares-variance-ratios-and-f-tests"><i class="fa fa-check"></i><b>14.3.2</b> Mean squares, variance ratios, and F-tests</a></li>
</ul></li>
<li class="chapter" data-level="14.4" data-path="introduction-to-one-way-anova.html"><a href="introduction-to-one-way-anova.html#different-kinds-of-anova-model"><i class="fa fa-check"></i><b>14.4</b> Different kinds of ANOVA model</a></li>
<li class="chapter" data-level="14.5" data-path="introduction-to-one-way-anova.html"><a href="introduction-to-one-way-anova.html#questions"><i class="fa fa-check"></i><b>14.5</b> Some common questions about ANOVA</a>
<ul>
<li class="chapter" data-level="14.5.1" data-path="introduction-to-one-way-anova.html"><a href="introduction-to-one-way-anova.html#can-anova-only-be-applied-to-experimental-data"><i class="fa fa-check"></i><b>14.5.1</b> Can ANOVA only be applied to experimental data?</a></li>
<li class="chapter" data-level="14.5.2" data-path="introduction-to-one-way-anova.html"><a href="introduction-to-one-way-anova.html#do-we-need-equal-replication"><i class="fa fa-check"></i><b>14.5.2</b> Do we need equal replication?</a></li>
<li class="chapter" data-level="14.5.3" data-path="introduction-to-one-way-anova.html"><a href="introduction-to-one-way-anova.html#can-anova-be-done-with-only-two-treatments"><i class="fa fa-check"></i><b>14.5.3</b> Can ANOVA be done with only two treatments?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path="one-way-anova-in-R.html"><a href="one-way-anova-in-R.html"><i class="fa fa-check"></i><b>15</b> One-way ANOVA in R</a>
<ul>
<li class="chapter" data-level="15.1" data-path="one-way-anova-in-R.html"><a href="one-way-anova-in-R.html#introduction-3"><i class="fa fa-check"></i><b>15.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="15.1.1" data-path="one-way-anova-in-R.html"><a href="one-way-anova-in-R.html#first-steps-1"><i class="fa fa-check"></i><b>15.1.1</b> First steps</a></li>
<li class="chapter" data-level="15.1.2" data-path="one-way-anova-in-R.html"><a href="one-way-anova-in-R.html#visualising-the-data-1"><i class="fa fa-check"></i><b>15.1.2</b> Visualising the data</a></li>
</ul></li>
<li class="chapter" data-level="15.2" data-path="one-way-anova-in-R.html"><a href="one-way-anova-in-R.html#model-fitting-and-significance-tests-1"><i class="fa fa-check"></i><b>15.2</b> Model fitting and significance tests</a>
<ul>
<li class="chapter" data-level="15.2.1" data-path="one-way-anova-in-R.html"><a href="one-way-anova-in-R.html#interpreting-the-results"><i class="fa fa-check"></i><b>15.2.1</b> Interpreting the results</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="one-way-anova-in-R.html"><a href="one-way-anova-in-R.html#summarise-results-anova"><i class="fa fa-check"></i><b>15.3</b> Presenting results</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="multiple-comparison-tests-chapter.html"><a href="multiple-comparison-tests-chapter.html"><i class="fa fa-check"></i><b>16</b> Multiple comparison tests</a>
<ul>
<li class="chapter" data-level="16.1" data-path="multiple-comparison-tests-chapter.html"><a href="multiple-comparison-tests-chapter.html#post-hoc-multiple-comparisons-tests"><i class="fa fa-check"></i><b>16.1</b> Post hoc multiple comparisons tests</a></li>
<li class="chapter" data-level="16.2" data-path="multiple-comparison-tests-chapter.html"><a href="multiple-comparison-tests-chapter.html#mult-comp-R"><i class="fa fa-check"></i><b>16.2</b> Tukey’s HSD test in R</a>
<ul>
<li class="chapter" data-level="16.2.1" data-path="multiple-comparison-tests-chapter.html"><a href="multiple-comparison-tests-chapter.html#how-to-summarise-multiple-comparison-results"><i class="fa fa-check"></i><b>16.2.1</b> How to summarise multiple-comparison results</a></li>
<li class="chapter" data-level="16.2.2" data-path="multiple-comparison-tests-chapter.html"><a href="multiple-comparison-tests-chapter.html#doing-it-the-easy-way"><i class="fa fa-check"></i><b>16.2.2</b> Doing it the easy way…</a></li>
</ul></li>
<li class="chapter" data-level="16.3" data-path="multiple-comparison-tests-chapter.html"><a href="multiple-comparison-tests-chapter.html#summarise"><i class="fa fa-check"></i><b>16.3</b> Summarising and presenting the results of a Tukey test</a></li>
</ul></li>
<li class="part"><span><b>VI Experimental Design</b></span></li>
<li class="chapter" data-level="17" data-path="principles-experimental-design.html"><a href="principles-experimental-design.html"><i class="fa fa-check"></i><b>17</b> Principles of experimental design</a>
<ul>
<li class="chapter" data-level="17.1" data-path="principles-experimental-design.html"><a href="principles-experimental-design.html#introduction-4"><i class="fa fa-check"></i><b>17.1</b> Introduction</a></li>
<li class="chapter" data-level="17.2" data-path="principles-experimental-design.html"><a href="principles-experimental-design.html#jargon-busting"><i class="fa fa-check"></i><b>17.2</b> Jargon busting</a></li>
<li class="chapter" data-level="17.3" data-path="principles-experimental-design.html"><a href="principles-experimental-design.html#replication"><i class="fa fa-check"></i><b>17.3</b> Replication</a>
<ul>
<li class="chapter" data-level="17.3.1" data-path="principles-experimental-design.html"><a href="principles-experimental-design.html#independence"><i class="fa fa-check"></i><b>17.3.1</b> Independence and pseudoreplication</a></li>
</ul></li>
<li class="chapter" data-level="17.4" data-path="principles-experimental-design.html"><a href="principles-experimental-design.html#controls"><i class="fa fa-check"></i><b>17.4</b> Controls</a></li>
<li class="chapter" data-level="17.5" data-path="principles-experimental-design.html"><a href="principles-experimental-design.html#confounded-and-noisy-experiments"><i class="fa fa-check"></i><b>17.5</b> Confounded and noisy experiments</a>
<ul>
<li class="chapter" data-level="17.5.1" data-path="principles-experimental-design.html"><a href="principles-experimental-design.html#confounding"><i class="fa fa-check"></i><b>17.5.1</b> Confounding</a></li>
<li class="chapter" data-level="17.5.2" data-path="principles-experimental-design.html"><a href="principles-experimental-design.html#noise"><i class="fa fa-check"></i><b>17.5.2</b> Noise</a></li>
</ul></li>
<li class="chapter" data-level="17.6" data-path="principles-experimental-design.html"><a href="principles-experimental-design.html#dealing-with-confounding-effects-and-noise"><i class="fa fa-check"></i><b>17.6</b> Dealing with confounding effects and noise</a>
<ul>
<li class="chapter" data-level="17.6.1" data-path="principles-experimental-design.html"><a href="principles-experimental-design.html#randomisation"><i class="fa fa-check"></i><b>17.6.1</b> Randomisation</a></li>
<li class="chapter" data-level="17.6.2" data-path="principles-experimental-design.html"><a href="principles-experimental-design.html#blocking"><i class="fa fa-check"></i><b>17.6.2</b> Blocking</a></li>
<li class="chapter" data-level="17.6.3" data-path="principles-experimental-design.html"><a href="principles-experimental-design.html#experimental-control"><i class="fa fa-check"></i><b>17.6.3</b> Experimental control</a></li>
<li class="chapter" data-level="17.6.4" data-path="principles-experimental-design.html"><a href="principles-experimental-design.html#additional-treatments-designing-in-unwanted-variation"><i class="fa fa-check"></i><b>17.6.4</b> Additional treatments: ‘designing in’ unwanted variation</a></li>
</ul></li>
<li class="chapter" data-level="17.7" data-path="principles-experimental-design.html"><a href="principles-experimental-design.html#ethics-and-practicality"><i class="fa fa-check"></i><b>17.7</b> Ethics and practicality</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="paired-sample-t-test.html"><a href="paired-sample-t-test.html"><i class="fa fa-check"></i><b>18</b> Paired-sample t-test</a>
<ul>
<li class="chapter" data-level="18.1" data-path="paired-sample-t-test.html"><a href="paired-sample-t-test.html#when-do-we-use-a-paired-sample-t-test"><i class="fa fa-check"></i><b>18.1</b> When do we use a paired-sample <em>t</em>-test?</a></li>
<li class="chapter" data-level="18.2" data-path="paired-sample-t-test.html"><a href="paired-sample-t-test.html#why-do-we-use-a-paired-sample-design"><i class="fa fa-check"></i><b>18.2</b> Why do we use a paired-sample design?</a></li>
<li class="chapter" data-level="18.3" data-path="paired-sample-t-test.html"><a href="paired-sample-t-test.html#how-do-you-carry-out-a-t-test-on-paired-samples"><i class="fa fa-check"></i><b>18.3</b> How do you carry out a <em>t</em>-test on paired samples?</a>
<ul>
<li class="chapter" data-level="18.3.1" data-path="paired-sample-t-test.html"><a href="paired-sample-t-test.html#assumptions-of-the-paired-sample-t-test"><i class="fa fa-check"></i><b>18.3.1</b> Assumptions of the paired-sample <em>t</em>-test</a></li>
</ul></li>
<li class="chapter" data-level="18.4" data-path="paired-sample-t-test.html"><a href="paired-sample-t-test.html#carrying-out-a-paired-sample-t-test-in-r"><i class="fa fa-check"></i><b>18.4</b> Carrying out a paired-sample <em>t</em>-test in R</a>
<ul>
<li class="chapter" data-level="18.4.1" data-path="paired-sample-t-test.html"><a href="paired-sample-t-test.html#using-the-paired-true-argument"><i class="fa fa-check"></i><b>18.4.1</b> Using the <code>paired = TRUE</code> argument</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="19" data-path="anova-for-randomised-block-designs.html"><a href="anova-for-randomised-block-designs.html"><i class="fa fa-check"></i><b>19</b> ANOVA for randomised block designs</a>
<ul>
<li class="chapter" data-level="19.1" data-path="anova-for-randomised-block-designs.html"><a href="anova-for-randomised-block-designs.html#randomised-complete-block-designs"><i class="fa fa-check"></i><b>19.1</b> Randomised Complete Block Designs</a></li>
<li class="chapter" data-level="19.2" data-path="anova-for-randomised-block-designs.html"><a href="anova-for-randomised-block-designs.html#analysing-an-rcbd-experiment"><i class="fa fa-check"></i><b>19.2</b> Analysing an RCBD experiment</a></li>
<li class="chapter" data-level="19.3" data-path="anova-for-randomised-block-designs.html"><a href="anova-for-randomised-block-designs.html#carrying-out-the-analysis-with-r"><i class="fa fa-check"></i><b>19.3</b> Carrying out the analysis with R</a></li>
<li class="chapter" data-level="19.4" data-path="anova-for-randomised-block-designs.html"><a href="anova-for-randomised-block-designs.html#are-there-disadvantages-to-randomised-block-designs"><i class="fa fa-check"></i><b>19.4</b> Are there disadvantages to randomised block designs?</a></li>
<li class="chapter" data-level="19.5" data-path="anova-for-randomised-block-designs.html"><a href="anova-for-randomised-block-designs.html#multiple-blocking-factors"><i class="fa fa-check"></i><b>19.5</b> Multiple blocking factors</a></li>
</ul></li>
<li class="part"><span><b>VII Checking and Fixing Models</b></span></li>
<li class="chapter" data-level="20" data-path="assumptions-and-diagnostics.html"><a href="assumptions-and-diagnostics.html"><i class="fa fa-check"></i><b>20</b> Assumptions and diagnostics</a>
<ul>
<li class="chapter" data-level="20.1" data-path="assumptions-and-diagnostics.html"><a href="assumptions-and-diagnostics.html#understanding-data"><i class="fa fa-check"></i><b>20.1</b> Understanding data</a></li>
<li class="chapter" data-level="20.2" data-path="assumptions-and-diagnostics.html"><a href="assumptions-and-diagnostics.html#assumptions-of-regression"><i class="fa fa-check"></i><b>20.2</b> Assumptions of regression</a></li>
<li class="chapter" data-level="20.3" data-path="assumptions-and-diagnostics.html"><a href="assumptions-and-diagnostics.html#regres-diagnose"><i class="fa fa-check"></i><b>20.3</b> Regression diagnostics</a>
<ul>
<li class="chapter" data-level="20.3.1" data-path="assumptions-and-diagnostics.html"><a href="assumptions-and-diagnostics.html#fitted-values"><i class="fa fa-check"></i><b>20.3.1</b> Fitted values</a></li>
<li class="chapter" data-level="20.3.2" data-path="assumptions-and-diagnostics.html"><a href="assumptions-and-diagnostics.html#checking-the-linearity-assumption"><i class="fa fa-check"></i><b>20.3.2</b> Checking the linearity assumption</a></li>
<li class="chapter" data-level="20.3.3" data-path="assumptions-and-diagnostics.html"><a href="assumptions-and-diagnostics.html#checking-the-normality-assumption"><i class="fa fa-check"></i><b>20.3.3</b> Checking the normality assumption</a></li>
<li class="chapter" data-level="20.3.4" data-path="assumptions-and-diagnostics.html"><a href="assumptions-and-diagnostics.html#checking-the-constant-variance-assumption"><i class="fa fa-check"></i><b>20.3.4</b> Checking the constant variance assumption</a></li>
</ul></li>
<li class="chapter" data-level="20.4" data-path="assumptions-and-diagnostics.html"><a href="assumptions-and-diagnostics.html#assumptions-of-one-way-anova"><i class="fa fa-check"></i><b>20.4</b> Assumptions of one-way ANOVA</a></li>
</ul></li>
<li class="chapter" data-level="21" data-path="regression-diagnostics-in-r.html"><a href="regression-diagnostics-in-r.html"><i class="fa fa-check"></i><b>21</b> Regression diagnostics in R</a>
<ul>
<li class="chapter" data-level="21.1" data-path="regression-diagnostics-in-r.html"><a href="regression-diagnostics-in-r.html#diagnostics-for-regression"><i class="fa fa-check"></i><b>21.1</b> Diagnostics for regression</a></li>
<li class="chapter" data-level="21.2" data-path="regression-diagnostics-in-r.html"><a href="regression-diagnostics-in-r.html#diagnostics-for-one-way-anova"><i class="fa fa-check"></i><b>21.2</b> Diagnostics for one-way ANOVA</a></li>
<li class="chapter" data-level="21.3" data-path="regression-diagnostics-in-r.html"><a href="regression-diagnostics-in-r.html#can-we-test-equality-of-variance"><i class="fa fa-check"></i><b>21.3</b> Can we test equality of variance?</a></li>
</ul></li>
<li class="chapter" data-level="22" data-path="transformations-chapter.html"><a href="transformations-chapter.html"><i class="fa fa-check"></i><b>22</b> Data transformations</a>
<ul>
<li class="chapter" data-level="22.1" data-path="transformations-chapter.html"><a href="transformations-chapter.html#transforms-introduction"><i class="fa fa-check"></i><b>22.1</b> Data that violate ANOVA assumptions</a></li>
<li class="chapter" data-level="22.2" data-path="transformations-chapter.html"><a href="transformations-chapter.html#ant-eg"><i class="fa fa-check"></i><b>22.2</b> Transformation: ANOVAs and <em>t</em>-tests</a>
<ul>
<li class="chapter" data-level="22.2.1" data-path="transformations-chapter.html"><a href="transformations-chapter.html#the-dataforaging-in-ants"><i class="fa fa-check"></i><b>22.2.1</b> The data—foraging in ants</a></li>
<li class="chapter" data-level="22.2.2" data-path="transformations-chapter.html"><a href="transformations-chapter.html#fit-the-model-and-checking-the-assumptions"><i class="fa fa-check"></i><b>22.2.2</b> Fit the model and checking the assumptions</a></li>
</ul></li>
<li class="chapter" data-level="22.3" data-path="transformations-chapter.html"><a href="transformations-chapter.html#carry-on"><i class="fa fa-check"></i><b>22.3</b> Carrying on anyway</a></li>
<li class="chapter" data-level="22.4" data-path="transformations-chapter.html"><a href="transformations-chapter.html#transform"><i class="fa fa-check"></i><b>22.4</b> Transforming the data</a>
<ul>
<li class="chapter" data-level="22.4.1" data-path="transformations-chapter.html"><a href="transformations-chapter.html#the-logarithmic-transformation"><i class="fa fa-check"></i><b>22.4.1</b> The logarithmic transformation</a></li>
<li class="chapter" data-level="22.4.2" data-path="transformations-chapter.html"><a href="transformations-chapter.html#presenting-results-from-analyses-of-transformed-data"><i class="fa fa-check"></i><b>22.4.2</b> Presenting results from analyses of transformed data</a></li>
</ul></li>
<li class="chapter" data-level="22.5" data-path="transformations-chapter.html"><a href="transformations-chapter.html#trans-types"><i class="fa fa-check"></i><b>22.5</b> Types of transformations</a>
<ul>
<li class="chapter" data-level="22.5.1" data-path="transformations-chapter.html"><a href="transformations-chapter.html#logarithms"><i class="fa fa-check"></i><b>22.5.1</b> Logarithms</a></li>
<li class="chapter" data-level="22.5.2" data-path="transformations-chapter.html"><a href="transformations-chapter.html#square-roots"><i class="fa fa-check"></i><b>22.5.2</b> Square roots</a></li>
<li class="chapter" data-level="22.5.3" data-path="transformations-chapter.html"><a href="transformations-chapter.html#arcsine-square-root"><i class="fa fa-check"></i><b>22.5.3</b> Arcsine square root</a></li>
<li class="chapter" data-level="22.5.4" data-path="transformations-chapter.html"><a href="transformations-chapter.html#squaring"><i class="fa fa-check"></i><b>22.5.4</b> Squaring</a></li>
<li class="chapter" data-level="22.5.5" data-path="transformations-chapter.html"><a href="transformations-chapter.html#situations-which-cannot-be-dealt-with-by-transformations"><i class="fa fa-check"></i><b>22.5.5</b> Situations which cannot be dealt with by transformations</a></li>
</ul></li>
<li class="chapter" data-level="22.6" data-path="transformations-chapter.html"><a href="transformations-chapter.html#what-about-other-kinds-of-models"><i class="fa fa-check"></i><b>22.6</b> What about other kinds of models?</a></li>
<li class="chapter" data-level="22.7" data-path="transformations-chapter.html"><a href="transformations-chapter.html#final-thoughts"><i class="fa fa-check"></i><b>22.7</b> Final thoughts</a></li>
</ul></li>
<li class="part"><span><b>VIII Frequency Data and Non-parametric Tests</b></span></li>
<li class="chapter" data-level="23" data-path="categorical-data-intro-chapter.html"><a href="categorical-data-intro-chapter.html"><i class="fa fa-check"></i><b>23</b> Categorical data</a>
<ul>
<li class="chapter" data-level="23.1" data-path="categorical-data-intro-chapter.html"><a href="categorical-data-intro-chapter.html#a-new-kind-of-distribution"><i class="fa fa-check"></i><b>23.1</b> A new kind of distribution</a></li>
<li class="chapter" data-level="23.2" data-path="categorical-data-intro-chapter.html"><a href="categorical-data-intro-chapter.html#types-of-test"><i class="fa fa-check"></i><b>23.2</b> Types of test</a>
<ul>
<li class="chapter" data-level="23.2.1" data-path="categorical-data-intro-chapter.html"><a href="categorical-data-intro-chapter.html#chi2-goodness-of-fit-test"><i class="fa fa-check"></i><b>23.2.1</b> <span class="math inline">\(\chi^{2}\)</span> goodness of fit test</a></li>
<li class="chapter" data-level="23.2.2" data-path="categorical-data-intro-chapter.html"><a href="categorical-data-intro-chapter.html#chi2-contingency-table-test"><i class="fa fa-check"></i><b>23.2.2</b> <span class="math inline">\(\chi^{2}\)</span> contingency table test</a></li>
<li class="chapter" data-level="23.2.3" data-path="categorical-data-intro-chapter.html"><a href="categorical-data-intro-chapter.html#the-assumptions-and-requirements-of-chi2-tests"><i class="fa fa-check"></i><b>23.2.3</b> The assumptions and requirements of <span class="math inline">\(\chi^{2}\)</span> tests</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="24" data-path="goodness-of-fit-tests.html"><a href="goodness-of-fit-tests.html"><i class="fa fa-check"></i><b>24</b> Goodness of fit tests</a>
<ul>
<li class="chapter" data-level="24.1" data-path="goodness-of-fit-tests.html"><a href="goodness-of-fit-tests.html#when-do-we-use-a-chi-square-goodness-of-fit-test"><i class="fa fa-check"></i><b>24.1</b> When do we use a chi-square goodness of fit test?</a></li>
<li class="chapter" data-level="24.2" data-path="goodness-of-fit-tests.html"><a href="goodness-of-fit-tests.html#how-does-the-chi-square-goodness-of-fit-test-work"><i class="fa fa-check"></i><b>24.2</b> How does the chi-square goodness of fit test work?</a>
<ul>
<li class="chapter" data-level="24.2.1" data-path="goodness-of-fit-tests.html"><a href="goodness-of-fit-tests.html#assumptions-of-the-chi-square-goodness-of-fit-test"><i class="fa fa-check"></i><b>24.2.1</b> Assumptions of the chi-square goodness of fit test</a></li>
</ul></li>
<li class="chapter" data-level="24.3" data-path="goodness-of-fit-tests.html"><a href="goodness-of-fit-tests.html#carrying-out-a-chi-square-goodness-of-fit-test-in-r"><i class="fa fa-check"></i><b>24.3</b> Carrying out a chi-square goodness of fit test in R</a>
<ul>
<li class="chapter" data-level="24.3.1" data-path="goodness-of-fit-tests.html"><a href="goodness-of-fit-tests.html#summarising-the-result-2"><i class="fa fa-check"></i><b>24.3.1</b> Summarising the result</a></li>
<li class="chapter" data-level="24.3.2" data-path="goodness-of-fit-tests.html"><a href="goodness-of-fit-tests.html#a-bit-more-about-goodness-of-fit-tests-in-r"><i class="fa fa-check"></i><b>24.3.2</b> A bit more about goodness of fit tests in R</a></li>
<li class="chapter" data-level="24.3.3" data-path="goodness-of-fit-tests.html"><a href="goodness-of-fit-tests.html#doing-it-the-long-way"><i class="fa fa-check"></i><b>24.3.3</b> Doing it the long way…</a></li>
</ul></li>
<li class="chapter" data-level="24.4" data-path="goodness-of-fit-tests.html"><a href="goodness-of-fit-tests.html#determining-appropriate-expected-values"><i class="fa fa-check"></i><b>24.4</b> Determining appropriate expected values</a></li>
</ul></li>
<li class="chapter" data-level="25" data-path="contingency-tables.html"><a href="contingency-tables.html"><i class="fa fa-check"></i><b>25</b> Contingency tables</a>
<ul>
<li class="chapter" data-level="25.1" data-path="contingency-tables.html"><a href="contingency-tables.html#when-do-we-use-a-chi-square-contingency-table-test"><i class="fa fa-check"></i><b>25.1</b> When do we use a chi-square contingency table test?</a></li>
<li class="chapter" data-level="25.2" data-path="contingency-tables.html"><a href="contingency-tables.html#how-does-the-chi-square-contingency-table-test-work"><i class="fa fa-check"></i><b>25.2</b> How does the chi-square contingency table test work?</a>
<ul>
<li class="chapter" data-level="25.2.1" data-path="contingency-tables.html"><a href="contingency-tables.html#assumptions-of-the-chi-square-contingency-table-test"><i class="fa fa-check"></i><b>25.2.1</b> Assumptions of the chi-square contingency table test</a></li>
</ul></li>
<li class="chapter" data-level="25.3" data-path="contingency-tables.html"><a href="contingency-tables.html#carrying-out-a-chi-square-contingency-table-test-in-r"><i class="fa fa-check"></i><b>25.3</b> Carrying out a chi-square contingency table test in R</a>
<ul>
<li class="chapter" data-level="25.3.1" data-path="contingency-tables.html"><a href="contingency-tables.html#step-1.-get-the-data-into-the-correct-format"><i class="fa fa-check"></i><b>25.3.1</b> Step 1. Get the data into the correct format</a></li>
<li class="chapter" data-level="25.3.2" data-path="contingency-tables.html"><a href="contingency-tables.html#step-2.-do-the-test"><i class="fa fa-check"></i><b>25.3.2</b> Step 2. Do the test</a></li>
<li class="chapter" data-level="25.3.3" data-path="contingency-tables.html"><a href="contingency-tables.html#summarising-the-result-3"><i class="fa fa-check"></i><b>25.3.3</b> Summarising the result</a></li>
</ul></li>
<li class="chapter" data-level="25.4" data-path="contingency-tables.html"><a href="contingency-tables.html#working-with-larger-tables"><i class="fa fa-check"></i><b>25.4</b> Working with larger tables</a></li>
</ul></li>
<li class="chapter" data-level="26" data-path="non-parametric-tests.html"><a href="non-parametric-tests.html"><i class="fa fa-check"></i><b>26</b> Non-parametric tests</a>
<ul>
<li class="chapter" data-level="26.1" data-path="non-parametric-tests.html"><a href="non-parametric-tests.html#what-is-non-par"><i class="fa fa-check"></i><b>26.1</b> What is a non-parametric test?</a></li>
<li class="chapter" data-level="26.2" data-path="non-parametric-tests.html"><a href="non-parametric-tests.html#why-when"><i class="fa fa-check"></i><b>26.2</b> Why use non-parametric tests … and when?</a>
<ul>
<li class="chapter" data-level="26.2.1" data-path="non-parametric-tests.html"><a href="non-parametric-tests.html#what-are-the-advantages"><i class="fa fa-check"></i><b>26.2.1</b> What are the advantages?</a></li>
<li class="chapter" data-level="26.2.2" data-path="non-parametric-tests.html"><a href="non-parametric-tests.html#what-are-the-disadvantages"><i class="fa fa-check"></i><b>26.2.2</b> What are the disadvantages?</a></li>
</ul></li>
<li class="chapter" data-level="26.3" data-path="non-parametric-tests.html"><a href="non-parametric-tests.html#non-par-intro"><i class="fa fa-check"></i><b>26.3</b> How does a non-parametric test work?</a></li>
<li class="chapter" data-level="26.4" data-path="non-parametric-tests.html"><a href="non-parametric-tests.html#non-parametric-equivalents"><i class="fa fa-check"></i><b>26.4</b> Non-parametric equivalents</a></li>
<li class="chapter" data-level="26.5" data-path="non-parametric-tests.html"><a href="non-parametric-tests.html#wilcoxon-signed-rank-test"><i class="fa fa-check"></i><b>26.5</b> Wilcoxon signed-rank test</a>
<ul>
<li class="chapter" data-level="26.5.1" data-path="non-parametric-tests.html"><a href="non-parametric-tests.html#leaf-damage-plant-defences-and-feeding-by-winter-moth-larvae"><i class="fa fa-check"></i><b>26.5.1</b> Leaf damage, plant defences and feeding by winter moth larvae</a></li>
</ul></li>
<li class="chapter" data-level="26.6" data-path="non-parametric-tests.html"><a href="non-parametric-tests.html#mann-whitney"><i class="fa fa-check"></i><b>26.6</b> The Mann-Whitney <em>U</em>-test</a>
<ul>
<li class="chapter" data-level="26.6.1" data-path="non-parametric-tests.html"><a href="non-parametric-tests.html#ant-foraging"><i class="fa fa-check"></i><b>26.6.1</b> Ant foraging</a></li>
</ul></li>
<li class="chapter" data-level="26.7" data-path="non-parametric-tests.html"><a href="non-parametric-tests.html#the-kruskal-wallis-test"><i class="fa fa-check"></i><b>26.7</b> The Kruskal-Wallis test</a>
<ul>
<li class="chapter" data-level="26.7.1" data-path="non-parametric-tests.html"><a href="non-parametric-tests.html#learning-in-cuttlefish"><i class="fa fa-check"></i><b>26.7.1</b> Learning in cuttlefish</a></li>
</ul></li>
<li class="chapter" data-level="26.8" data-path="non-parametric-tests.html"><a href="non-parametric-tests.html#spearmans-rank-correlation"><i class="fa fa-check"></i><b>26.8</b> Spearman’s rank correlation</a>
<ul>
<li class="chapter" data-level="26.8.1" data-path="non-parametric-tests.html"><a href="non-parametric-tests.html#grouse-lekking"><i class="fa fa-check"></i><b>26.8.1</b> Grouse lekking</a></li>
</ul></li>
<li class="chapter" data-level="26.9" data-path="non-parametric-tests.html"><a href="non-parametric-tests.html#parting-words"><i class="fa fa-check"></i><b>26.9</b> Parting words</a></li>
</ul></li>
<li class="appendix"><span><b>Supplementary Material</b></span></li>
<li class="chapter" data-level="A" data-path="choosing-models-and-tests.html"><a href="choosing-models-and-tests.html"><i class="fa fa-check"></i><b>A</b> Choosing models and tests</a>
<ul>
<li class="chapter" data-level="A.1" data-path="introduction-to-one-way-anova.html"><a href="introduction-to-one-way-anova.html#intro"><i class="fa fa-check"></i><b>A.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="A.1.1" data-path="choosing-models-and-tests.html"><a href="choosing-models-and-tests.html#do-we-need-to-carry-out-a-statistical-analysis"><i class="fa fa-check"></i><b>A.1.1</b> Do we need to carry out a statistical analysis?</a></li>
</ul></li>
<li class="chapter" data-level="A.2" data-path="choosing-models-and-tests.html"><a href="choosing-models-and-tests.html#getting-started"><i class="fa fa-check"></i><b>A.2</b> Getting started</a></li>
<li class="chapter" data-level="A.3" data-path="choosing-models-and-tests.html"><a href="choosing-models-and-tests.html#a-key-to-choosing-statistical-models-and-tests"><i class="fa fa-check"></i><b>A.3</b> A key to choosing statistical models and tests</a></li>
<li class="chapter" data-level="A.4" data-path="choosing-models-and-tests.html"><a href="choosing-models-and-tests.html#four-questions"><i class="fa fa-check"></i><b>A.4</b> Four main types of question</a></li>
<li class="chapter" data-level="A.5" data-path="choosing-models-and-tests.html"><a href="choosing-models-and-tests.html#qu1"><i class="fa fa-check"></i><b>A.5</b> Question 1 — Comparison of group means or medians</a>
<ul>
<li class="chapter" data-level="A.5.1" data-path="choosing-models-and-tests.html"><a href="choosing-models-and-tests.html#question-1-how-many-groups"><i class="fa fa-check"></i><b>A.5.1</b> Question 1 How many groups?</a></li>
<li class="chapter" data-level="A.5.2" data-path="choosing-models-and-tests.html"><a href="choosing-models-and-tests.html#question-1-single-group"><i class="fa fa-check"></i><b>A.5.2</b> [Question 1] Single group</a></li>
<li class="chapter" data-level="A.5.3" data-path="choosing-models-and-tests.html"><a href="choosing-models-and-tests.html#question-1-two-groups"><i class="fa fa-check"></i><b>A.5.3</b> [Question 1] Two groups</a></li>
<li class="chapter" data-level="A.5.4" data-path="choosing-models-and-tests.html"><a href="choosing-models-and-tests.html#question-1-more-than-two-groups"><i class="fa fa-check"></i><b>A.5.4</b> [Question 1] More than two groups</a></li>
</ul></li>
<li class="chapter" data-level="A.6" data-path="choosing-models-and-tests.html"><a href="choosing-models-and-tests.html#qu2"><i class="fa fa-check"></i><b>A.6</b> Question 2 – Associations between two variables?</a>
<ul>
<li class="chapter" data-level="A.6.1" data-path="choosing-models-and-tests.html"><a href="choosing-models-and-tests.html#question-2-testing-y-as-a-function-of-x-or-an-association-between-x-and-y"><i class="fa fa-check"></i><b>A.6.1</b> [Question 2] Testing <span class="math inline">\(y\)</span> as a function of <span class="math inline">\(x\)</span>, or an association between <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>?</a></li>
</ul></li>
<li class="chapter" data-level="A.7" data-path="choosing-models-and-tests.html"><a href="choosing-models-and-tests.html#qu4"><i class="fa fa-check"></i><b>A.7</b> Question 3 — Frequencies of categorical data</a></li>
<li class="chapter" data-level="A.8" data-path="choosing-models-and-tests.html"><a href="choosing-models-and-tests.html#var-cat"><i class="fa fa-check"></i><b>A.8</b> Variables or categories?</a>
<ul>
<li class="chapter" data-level="A.8.1" data-path="choosing-models-and-tests.html"><a href="choosing-models-and-tests.html#anova-vs.-regression"><i class="fa fa-check"></i><b>A.8.1</b> ANOVA vs. regression</a></li>
<li class="chapter" data-level="A.8.2" data-path="choosing-models-and-tests.html"><a href="choosing-models-and-tests.html#making-categories-out-of-continuous-measures"><i class="fa fa-check"></i><b>A.8.2</b> Making categories out of continuous measures</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="B" data-path="writing-a-scientific-report.html"><a href="writing-a-scientific-report.html"><i class="fa fa-check"></i><b>B</b> Writing a scientific report</a>
<ul>
<li class="chapter" data-level="B.1" data-path="writing-a-scientific-report.html"><a href="writing-a-scientific-report.html#introduction-5"><i class="fa fa-check"></i><b>B.1</b> Introduction</a></li>
<li class="chapter" data-level="B.2" data-path="writing-a-scientific-report.html"><a href="writing-a-scientific-report.html#the-structure-of-a-scientific-report"><i class="fa fa-check"></i><b>B.2</b> The structure of a scientific report</a>
<ul>
<li class="chapter" data-level="B.2.1" data-path="writing-a-scientific-report.html"><a href="writing-a-scientific-report.html#title"><i class="fa fa-check"></i><b>B.2.1</b> Title</a></li>
<li class="chapter" data-level="B.2.2" data-path="writing-a-scientific-report.html"><a href="writing-a-scientific-report.html#abstract-or-summary"><i class="fa fa-check"></i><b>B.2.2</b> Abstract or Summary</a></li>
<li class="chapter" data-level="B.2.3" data-path="writing-a-scientific-report.html"><a href="writing-a-scientific-report.html#introduction-6"><i class="fa fa-check"></i><b>B.2.3</b> Introduction</a></li>
<li class="chapter" data-level="B.2.4" data-path="writing-a-scientific-report.html"><a href="writing-a-scientific-report.html#methods"><i class="fa fa-check"></i><b>B.2.4</b> Methods</a></li>
<li class="chapter" data-level="B.2.5" data-path="writing-a-scientific-report.html"><a href="writing-a-scientific-report.html#results"><i class="fa fa-check"></i><b>B.2.5</b> Results</a></li>
<li class="chapter" data-level="B.2.6" data-path="writing-a-scientific-report.html"><a href="writing-a-scientific-report.html#discussion"><i class="fa fa-check"></i><b>B.2.6</b> Discussion</a></li>
<li class="chapter" data-level="B.2.7" data-path="writing-a-scientific-report.html"><a href="writing-a-scientific-report.html#acknowledgements"><i class="fa fa-check"></i><b>B.2.7</b> Acknowledgements</a></li>
<li class="chapter" data-level="B.2.8" data-path="writing-a-scientific-report.html"><a href="writing-a-scientific-report.html#literature-cited-references"><i class="fa fa-check"></i><b>B.2.8</b> Literature cited / References</a></li>
<li class="chapter" data-level="B.2.9" data-path="writing-a-scientific-report.html"><a href="writing-a-scientific-report.html#appendices"><i class="fa fa-check"></i><b>B.2.9</b> Appendices</a></li>
</ul></li>
<li class="chapter" data-level="B.3" data-path="writing-a-scientific-report.html"><a href="writing-a-scientific-report.html#presenting-species-names"><i class="fa fa-check"></i><b>B.3</b> Presenting species names</a></li>
<li class="chapter" data-level="B.4" data-path="writing-a-scientific-report.html"><a href="writing-a-scientific-report.html#approaches-to-writing"><i class="fa fa-check"></i><b>B.4</b> Approaches to writing</a>
<ul>
<li class="chapter" data-level="B.4.1" data-path="writing-a-scientific-report.html"><a href="writing-a-scientific-report.html#a-last-piece-of-advice"><i class="fa fa-check"></i><b>B.4.1</b> A last piece of advice…</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introductory Biostatistics with R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="assumptions-and-diagnostics" class="section level1" number="20">
<h1><span class="header-section-number">Chapter 20</span> Assumptions and diagnostics</h1>
<p>We often have a statistical analysis in mind when we collect some data. Though it can be tempting to jump straight into that analysis without first examining the data, this is seldom a good idea. We began each investigation in the last few chapters by inspecting the data set to understand what it was telling us. The initial inspection also provides an opportunity to evaluate whether or not our planned analysis assumptions are likely to be violated.</p>
<p>Assumptions are important. We learnt in previous chapters that regression and ANOVA are special cases of the general linear model. This is a parametric model, which makes several assumptions about the data that we need to be aware of. If our data do not meet those assumptions, at least approximately, then we cannot rely on the results given by any associated tests. This chapter aims to review what those assumptions are for simple regression and regression and one-way ANOVA models.</p>
<div id="understanding-data" class="section level2" number="20.1">
<h2><span class="header-section-number">20.1</span> Understanding data</h2>
<p>We’ve been using ‘well-behaved’ data sets in this book so far, which tends to give the impression that visual inspections of the data are not all that necessary. Here’s an example of why it matters. Imagine we are interested in quantifying the relationship between two variables, called <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>. We might be tempted to carry out a linear regression analysis without first inspecting these data to get straight to ‘the answer’: the coefficients of the linear regression model. This could be very misleading. Take a look at these four scatter plots:</p>
<p><img src="intro-bio-stats-book_files/figure-html/unnamed-chunk-149-1.png" width="60%" style="display: block; margin: auto;" /></p>
<p>These four artificial data sets were constructed by the statistician Francis Anscombe. The means and variances of <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> are nearly identical in all four data sets. What’s more, the intercepts and slopes of the best fit regression lines are almost identical—they are 3.0 and 0.5, respectively. The nature of the relationship between <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> is quite obviously different among the four cases:</p>
<ol style="list-style-type: decimal">
<li><p>“Case 1” shows two linearly related, normally distributed variables. This is the kind of data we often hope for in a statistical analysis.</p></li>
<li><p>“Case 2” shows two variables that are not normally distributed, but there is a perfect non-linear relationship between the two.</p></li>
<li><p>“Case 3” shows an example the variables are perfectly linearly associated for all but one observation which ruins the perfect relationship.</p></li>
<li><p>“Case 4” shows an example where a single outlier generates an apparent relationship where the two variables are otherwise unrelated.</p></li>
</ol>
<p>Each plot tells a different story about the relationship between <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>, yet the linear regression model says the relationship is the same in each case. These are obviously somewhat pathological examples, but they illustrate the kinds of issues that can, and do, arise with real data. There is a real risk we will apply an inappropriate analysis if we fail to detect these kinds of problems.</p>
<p>Every statistical model makes certain assumptions about the data<a href="#fn17" class="footnote-ref" id="fnref17"><sup>17</sup></a>. Even if a dataset doesn’t exhibit the pronounced problems seen in the Anscombe examples, we still need to assess whether the assumptions of the statistical model we want to use are likely to be valid. For example, when working with a linear regression model, we started with a scatter plot of the response variable vs the predictor variable. This allowed us to assess whether the two variables are linearly related. However, as we noted at the time, linearity is not the only assumption we need to consider when carrying out a linear regression. In the rest of this chapter, we’ll go through the remaining regression assumptions and then consider the assumptions for a one-way ANOVA.</p>
<p>In the later regression diagnostics chapters, we’ll move on to how to check whether these assumptions are valid with your data.</p>
</div>
<div id="assumptions-of-regression" class="section level2" number="20.2">
<h2><span class="header-section-number">20.2</span> Assumptions of regression</h2>
<p>Let’s consider each of the assumptions of a regression in their approximate order of importance:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Independence.</strong> The residuals must be independent. Another way of stating this assumption is that the value of each residual does not depend on the value of any others. This can be difficult to check. If the data are from a carefully designed experiment, everything should be OK. If the data are observational, then we need to be a lot more careful. This assumption matters because when the residuals are not independent, any <em>p</em>-values we generate will be unreliable.</p></li>
<li><p><strong>Measurement scale.</strong> The response (<span class="math inline">\(y\)</span>) and predictor (<span class="math inline">\(x\)</span>) variables are measured on an interval or ratio scale. It doesn’t really make sense to use categorical data in a regression<a href="#fn18" class="footnote-ref" id="fnref18"><sup>18</sup></a>. This one is easy to assess.</p></li>
<li><p><strong>Linearity.</strong> The relationship between the predictor <span class="math inline">\(x\)</span> variable and the response <span class="math inline">\(y\)</span> variable is linear. There is little point in fitting a straight line to data that don’t form a straight-line relationship. There may also be circumstances in which it is theoretically unlikely for a relationship to be linear, e.g. a linear relationship will not well describe the length and weight of an animal because weight is roughly a cubic function of length. If the data fail this assumption, applying a mathematical transformation of <span class="math inline">\(x\)</span> or <span class="math inline">\(y\)</span> can help. We will come back to this idea in the later data transformations chapter.</p></li>
<li><p><strong>Constant variance.</strong> The variance of the residuals is constant. This assumption essentially means the variability of the residuals is not related to the value of the predictor <span class="math inline">\(x\)</span> variable. It is violated if the magnitude of the residuals increase or decrease markedly as <span class="math inline">\(x\)</span> gets larger. If the data fail this assumption then again, sometimes applying a mathematical transformation of <span class="math inline">\(y\)</span> will help.</p></li>
<li><p><strong>Normality.</strong> The residuals are drawn from a normal distribution. This essentially means that for a particular value of <span class="math inline">\(x\)</span> we would expect a range of responses in <span class="math inline">\(y\)</span> which follow a normal distribution. The distribution of the deviations of <span class="math inline">\(y\)</span> from the fitted line (the residuals) is assumed to be normal, not the raw <span class="math inline">\(y\)</span> values. This means that we can generally only test this assumption <em>after</em> the line has been fitted. It is hard to evaluate this assumption by looking at the raw data.</p></li>
<li><p><strong>Measurement error.</strong> The values of the predictor <span class="math inline">\(x\)</span> variable are determined with negligible measurement error<a href="#fn19" class="footnote-ref" id="fnref19"><sup>19</sup></a>. It is usually impossible to obtain the <span class="math inline">\(x\)</span> values with absolutely no measurement error, but the error <span class="math inline">\(x\)</span> in should at least be much smaller than that in the <span class="math inline">\(y\)</span> values. For example, in a thermal tolerance experiment, the temperature values set by the experimenter will often have low error, so it is fine to use ordinary simple regression.</p></li>
</ol>
<p>Assumptions 1 (independence), 2 (measurement scale) and 6 (measurement error) are features of experimental design and the data collection protocol. If one of these assumptions is violated, there’s not much we can do about that after the data have been collected. This is why it’s so important to consider how you will collect and analyse your data before you invest time doing it. You don’t want to spend vast amounts of time and effort collecting data that you won’t be able to analyse.</p>
<p>What about the remaining assumptions: linearity, constant variance and normality? These can be checked by using a set of tools called ‘regression diagnostics.’ Regression diagnostics use properties of the fitted model to understand how well it fits the data and thereby evaluate the model assumptions. This means they can only be applied after we have fitted a model to the data.</p>
</div>
<div id="regres-diagnose" class="section level2" number="20.3">
<h2><span class="header-section-number">20.3</span> Regression diagnostics</h2>
<p>We’ll learn how to use regression diagnostics by working through an example. A survey was carried out to establish whether the abundance of hedgerows in agricultural land had an effect on the abundance of grey partridge. From an area of agricultural land covering several farms, 40 plots were selected which had land uses as similar as possible but differed in the density of hedgerows (km hedgerow per km<sup>2</sup>). The density of partridges was established by visiting all fields in a study plot once immediately after dawn and once just before dusk, when partridges are most likely to be seen. Counts of birds observed were made on each visit and the dawn and dusk data were averaged to give a value for partridge abundance for each study plot.</p>
<p>Assumption 2 (measurement scale) is easy to evaluate. Assumptions 1 (independence) and 6 (measurement error) can’t be checked by just looking at the data; we have to think about the data to decide if there are any obvious reasons why they might not be valid. We’ll assume here that the independence assumption is true.</p>
<p>As hedges cannot move, there should be relatively little measurement error in the values of the predictor variable (hedgerow density) in this study. This leaves assumptions 3 (linearity), 4 (constant variance) and 5 (normality). There is a specific diagnostic plot for each of these.</p>
<div id="section-12" class="section level4 unnumbered infobox action">
<h4 class="unnumbered"></h4>
<p>These data can be found in the ‘PARTRIDG_BIGSTUDY.CSV’ file. The code below assumes they have been read into a tibble called <code>partridge</code>. Set that up if you plan to work along.</p>
</div>
<p>The density of hedgerows (km per km<sup>2</sup>) is in the <code>Hedgerow</code> variable and the density of partridges (no. per km<sup>2</sup>) is in the <code>Partridge</code> variable:</p>
<div class="sourceCode" id="cb136"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb136-1"><a href="assumptions-and-diagnostics.html#cb136-1" aria-hidden="true" tabindex="-1"></a><span class="fu">glimpse</span>(partridge)</span></code></pre></div>
<pre><code>## Rows: 40
## Columns: 2
## $ Hedgerow  &lt;dbl&gt; 5.8, 6.0, 6.9, 7.3, 8.1, 9.3, 10.4, 12.3, 12.6, 13.3, 13.6, …
## $ Partridge &lt;dbl&gt; 1.7, 3.4, 9.1, 12.5, 5.1, 9.2, 7.2, 10.7, 2.0, 19.3, 17.7, 9…</code></pre>
<p>We can show the relationship between <code>Partridge</code> and <code>Hedgerow</code> using a scatter plot:</p>
<p><img src="intro-bio-stats-book_files/figure-html/unnamed-chunk-153-1.png" width="384" style="display: block; margin: auto;" /></p>
<div id="section-13" class="section level4 unnumbered infobox action">
<h4 class="unnumbered"></h4>
<p>Spend some time looking at that plot. Does it look like these data satisfy the linearity assumption?</p>
</div>
<div id="fitted-values" class="section level3" number="20.3.1">
<h3><span class="header-section-number">20.3.1</span> Fitted values</h3>
<p>In order to understand regression diagnostics we have to know what a <strong>fitted value</strong> is. The phrase ‘fitted value’ is just another expression for ‘predicted value.’ Look at the plot below:</p>
<p><img src="intro-bio-stats-book_files/figure-html/unnamed-chunk-154-1.png" width="384" style="display: block; margin: auto;" /></p>
<p>This shows the raw data (black points), the line of best fit (blue line), the residuals (the vertical grey lines), and the fitted values (red points).</p>
<p>That line of best fit was created using the workflow we introduced in the earlier regression chapter. We find the fitted values by drawing a vertical line from each observation to the line of best fit. The values of the response variable (<code>Partridge</code> in this case) at the point where these touch the line of best fit are the ‘fitted values.’ This means the fitted values are just predictions from the statistical model generated for each value of the predictor variable. We can use the <code>fitted</code> function to extract these from a fitted model:</p>
<div class="sourceCode" id="cb138"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb138-1"><a href="assumptions-and-diagnostics.html#cb138-1" aria-hidden="true" tabindex="-1"></a><span class="fu">fitted</span>(partridge_model)</span></code></pre></div>
<pre><code>##     1     2     3     4     5     6     7     8     9    10    11    12    13 
## -11.6 -11.0  -8.4  -7.2  -4.9  -1.4   1.8   7.3   8.2  10.2  11.1  14.3  22.1 
##    14    15    16    17    18    19    20    21    22    23    24    25    26 
##  22.7  27.0  28.2  28.8  35.2  37.8  38.1  43.0  45.4  48.3  52.3  57.6  61.0 
##    27    28    29    30    31    32    33    34    35    36    37    38    39 
##  62.2  62.2  63.7  68.3  71.2  77.0  86.6  87.8  88.1  90.4  91.6  96.8  98.0 
##    40 
## 101.7</code></pre>
<div id="section-14" class="section level4 unnumbered infobox action">
<h4 class="unnumbered"></h4>
<p>Notice that some of the fitted values are below zero. Why do we see negative fitted values? This doesn’t make much sense biologically (negative partridges?). Do you think it is a problem?</p>
</div>
</div>
<div id="checking-the-linearity-assumption" class="section level3" number="20.3.2">
<h3><span class="header-section-number">20.3.2</span> Checking the linearity assumption</h3>
<p>The linearity assumption states that the general relationship between the response and predictor variable should look like a straight line. We can evaluate this assumption by constructing a <strong>residuals vs fitted values</strong> plot.</p>
<p>We can make this in two steps. First use the <code>fitted</code> and <code>resid</code> functions to construct a data frame containing the fitted values and residuals from the model (called <code>plt_data</code>):</p>
<div class="sourceCode" id="cb140"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb140-1"><a href="assumptions-and-diagnostics.html#cb140-1" aria-hidden="true" tabindex="-1"></a>plt_data <span class="ot">&lt;-</span> </span>
<span id="cb140-2"><a href="assumptions-and-diagnostics.html#cb140-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">data.frame</span>(<span class="at">Fitted =</span> <span class="fu">fitted</span>(partridge_model), </span>
<span id="cb140-3"><a href="assumptions-and-diagnostics.html#cb140-3" aria-hidden="true" tabindex="-1"></a>             <span class="at">Resids =</span>  <span class="fu">resid</span>(partridge_model))</span></code></pre></div>
<p>Once we have made this data frame, we use <code>ggplot2</code> to plot the residuals against the fitted values:</p>
<div class="sourceCode" id="cb141"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb141-1"><a href="assumptions-and-diagnostics.html#cb141-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(plt_data, <span class="fu">aes</span>(<span class="at">x =</span> Fitted, <span class="at">y =</span> Resids)) <span class="sc">+</span> </span>
<span id="cb141-2"><a href="assumptions-and-diagnostics.html#cb141-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span> </span>
<span id="cb141-3"><a href="assumptions-and-diagnostics.html#cb141-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">&quot;Fitted values&quot;</span>) <span class="sc">+</span> <span class="fu">ylab</span>(<span class="st">&quot;Residuals&quot;</span>)</span></code></pre></div>
<p><img src="intro-bio-stats-book_files/figure-html/unnamed-chunk-158-1.png" width="384" style="display: block; margin: auto;" /></p>
<p>This plot indicates that the residuals tend to be positive at the largest and smallest fitted values and that they are generally negative in the middle of the range. This U-shaped pattern is indicative of a potential problem with our model. It shows us there is some feature of the relationship between the predictor and response variables that is not accommodated by the simple linear regression model we used.</p>
<p>The U-shape indicates that the relationship is non-linear and that it ‘curves upward.’ We can see where this pattern comes from when we look at the raw data and the fitted model:</p>
<p><img src="intro-bio-stats-book_files/figure-html/unnamed-chunk-159-1.png" width="384" style="display: block; margin: auto;" /></p>
<p>There is some curvature in the relationship between partridge counts and hedgerow density, yet we fitted a straight line through the data. The U-shape in the residuals vs fitted value plot comes from an ‘accelerating’ (or ‘convex’) relationship between the response and predictor variables that we failed to capture with the model.</p>
<p>What other kinds of patterns might we see in a residuals vs fitted value plot? Two paterns are particularly common: U-shapes and hump-shapes. Look at the two artificial data sets below:</p>
<p><img src="intro-bio-stats-book_files/figure-html/unnamed-chunk-161-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>The left-hand plot is similar to the partridge data: it exhibits a curved, accelerating relationship between the response variable and the predictor variable. The right-hand plot shows a different kind of relationship: a curved, decelerating relationship between the two variables. Look what happens if we fit a linear model to each of these data sets and then visualise the corresponding residuals vs fitted value plots:</p>
<p><img src="intro-bio-stats-book_files/figure-html/unnamed-chunk-162-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Here we see the characteristic U-shape and hump-shape patterns we mentioned above, these occur when there is an accelerating or decelerating relationship respectively between the response variable and predictor variable.</p>
<p>This may seem like a lot of extra work to evaluate an aspect of the model that we can assess by just plotting the raw data. This is true when we are working with a simple linear regression model. However, it is much harder to evaluate the linearity assumption when working with more complicated models that include more than one predictor variable<a href="#fn20" class="footnote-ref" id="fnref20"><sup>20</sup></a>. In these situations, a residuals vs fitted values plot gives us a powerful way to evaluate whether or not the assumption of a linear relationship is reasonable.</p>
<p>That’s enough about residuals vs fitted values plots. Let’s move on to the normality evaluation.</p>
</div>
<div id="checking-the-normality-assumption" class="section level3" number="20.3.3">
<h3><span class="header-section-number">20.3.3</span> Checking the normality assumption</h3>
<p>How should we evaluate the normality assumption of linear regression? That is, how do we assess whether or not the residuals are drawn from a normal distribution? We could extract the residuals from a model and plot their distribution, but a more powerful graphical technique is available to us: the <strong>normal probability plot</strong>.</p>
<p>The normal probability plot is used to identify departures from normality. If we know what we are looking for, we can identify many different kinds of problems, but to keep life simple we will focus on the most common type of assessment: determining whether or not the distribution of residuals is excessively <strong>skewed</strong>. Remember the concept of distributional skew? A skewed distribution is just one that is not symmetric. For example, the first distribution below is skewed to the left (‘negative skew’), the second is skewed to the right (‘positive skew’), and the third is symmetric (‘zero skew’):</p>
<p><img src="intro-bio-stats-book_files/figure-html/unnamed-chunk-163-1.png" width="672" /></p>
<p>The skewness in the first two distributions is easy to spot because they contain a lot of data and the skewness is quite pronounced. A normal probability plot allows us to pick up potential problems when we are not so lucky. The methodology underlying the construction of a normal probability plot is quite technical, so we will only give a flavour here.</p>
<p>Don’t worry if the next segment is confusing—interpreting a normal probability plot is much easier than making one.</p>
<p>We’ll work with the partridge example again. We start by extracting the residuals from the fitted model into a vector, using the <code>resids</code> function, and then standardise these by dividing them by their standard deviation:</p>
<div class="sourceCode" id="cb142"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb142-1"><a href="assumptions-and-diagnostics.html#cb142-1" aria-hidden="true" tabindex="-1"></a>mod_resids <span class="ot">&lt;-</span> <span class="fu">resid</span>(partridge_model)</span>
<span id="cb142-2"><a href="assumptions-and-diagnostics.html#cb142-2" aria-hidden="true" tabindex="-1"></a>mod_resids <span class="ot">&lt;-</span> mod_resids <span class="sc">/</span> <span class="fu">sd</span>(mod_resids)</span></code></pre></div>
<p>The standardisation step is not essential, but dividing the raw residuals by their standard deviation ensures that the standard deviation of the new residuals is equal to 1. Standardising the residuals like this makes it a little easier to compare more than one normal probability plot. We call these new residuals the ‘standardised residuals.’</p>
<p>The next step is to find the rank order of each residual. That is, we sort the data from lowest to highest and find the position of each case in the sequence (this is its ‘rank’). The function <code>order</code> can do this:</p>
<div class="sourceCode" id="cb143"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb143-1"><a href="assumptions-and-diagnostics.html#cb143-1" aria-hidden="true" tabindex="-1"></a>resid_order <span class="ot">&lt;-</span> <span class="fu">order</span>(mod_resids)</span>
<span id="cb143-2"><a href="assumptions-and-diagnostics.html#cb143-2" aria-hidden="true" tabindex="-1"></a>resid_order</span></code></pre></div>
<pre><code>##  [1] 35 27 30 32 22 13 23 21 17 15 14 26 24 28 25  9 40 12 20 19 16 29 18  8  7
## [26] 11 31 10 38  5  6  1  2  3 34  4 33 37 36 39</code></pre>
<p>This tells us that the first residual is the 35th largest, the second is the 27th largest, the third is the 30th largest, and so on.</p>
<p>The last step is the tricky one. Once we have established the rank order of the residuals, we ask the following question: if the residuals were drawn from a normal distribution, what is their most likely value, based on their rank? We can’t explain how to do this without delving into the mathematics of distributions, so this will have to be a ‘trust us’ situation.</p>
<p>As usual, R can do the hard calculations for us. In fact, we don’t even need the ranks—we just calculated them to help us explain what happens when we build a normal probability plot. The function we need is called <code>qqnorm</code>:</p>
<div class="sourceCode" id="cb145"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb145-1"><a href="assumptions-and-diagnostics.html#cb145-1" aria-hidden="true" tabindex="-1"></a>all_resids <span class="ot">&lt;-</span> <span class="fu">qqnorm</span>(mod_resids, <span class="at">plot.it =</span> <span class="cn">FALSE</span>)</span>
<span id="cb145-2"><a href="assumptions-and-diagnostics.html#cb145-2" aria-hidden="true" tabindex="-1"></a>all_resids <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(all_resids)</span></code></pre></div>
<p>The <code>qqnorm</code> doesn’t produce a data frame by default, so we converted the result using a function called <code>as.data.frame</code> (this extra little step isn’t all that important).</p>
<p>The <code>all_resids</code> object is now a data frame with two variables: <code>x</code> contains the theoretical values of normally distributed residuals, based on the rank orders of the residuals from the model, and <code>y</code> contains the standardised residuals. Here are the first 10 values:</p>
<div class="sourceCode" id="cb146"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb146-1"><a href="assumptions-and-diagnostics.html#cb146-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(all_resids, <span class="dv">10</span>)</span></code></pre></div>
<pre><code>##             x          y
## 1   0.7977768  0.6855052
## 2   0.8871466  0.7431596
## 3   0.9842350  0.9021176
## 4   1.2133396  1.0174265
## 5   0.6356570  0.5162945
## 6   0.7143674  0.5478778
## 7   0.2858409  0.2800927
## 8   0.2211187  0.1759340
## 9  -0.2858409 -0.3173156
## 10  0.4887764  0.4693592</code></pre>
<p>Finally, we can plot these against one another to make a normal probability plot:</p>
<div class="sourceCode" id="cb148"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb148-1"><a href="assumptions-and-diagnostics.html#cb148-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(all_resids, <span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> y)) <span class="sc">+</span> </span>
<span id="cb148-2"><a href="assumptions-and-diagnostics.html#cb148-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span> <span class="fu">geom_abline</span>(<span class="at">intercept =</span> <span class="dv">0</span>, <span class="at">slope =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb148-3"><a href="assumptions-and-diagnostics.html#cb148-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">&quot;Theoretical Value&quot;</span>) <span class="sc">+</span> <span class="fu">ylab</span>(<span class="st">&quot;Standardised Residual&quot;</span>)</span></code></pre></div>
<p><img src="intro-bio-stats-book_files/figure-html/unnamed-chunk-168-1.png" width="384" style="display: block; margin: auto;" /></p>
<p>We used <code>geom_abline(intercept = 0, slope = 1)</code> to add the one-to-one (1:1) line. We haven’t used this function before and we won’t need it again. The one-to-one line is just a line with a slope of 1 and an intercept of 0—if an <span class="math inline">\(x\)</span> value and <span class="math inline">\(y\)</span> value are equal their corresponding point will lie on this line.</p>
<p>Don’t worry too much if those calculations seem opaque. At the beginning of this section, we said that it’s not essential to understand how a normal probability plot is constructed. It is important to know how to interpret one. The critical feature to look out for is the positioning of the points relative to the 1:1 line. If the residuals were drawn from a normal distribution, they should generally match the theoretical values, i.e. the points should lie on the 1:1 line.</p>
<p>That is exactly what we see in the partridge example. A couple of the more extreme values diverge a little, but this isn’t something to worry about. We never expect to see a perfect 1:1 relationship in these kinds of plots. The vast majority of the points are very close to the 1:1 line though, which provides strong evidence that the residuals probably are sampled from a normal distribution.</p>
<p>What does a normal probability plot look like when residuals are not consistent with the normality assumption? Deviations from a straight line suggest departures from normality. How do right skew (‘positive skew’) and left skew (‘negative skew’) manifest themselves in a normal probability plot? Here is the normal probability plot produced using data from the left-skewed distribution above:</p>
<p><img src="intro-bio-stats-book_files/figure-html/unnamed-chunk-169-1.png" width="384" style="display: block; margin: auto;" /></p>
<p>Rather than a straight line, we see a decelerating curved line. This is the signature of residuals that are non-normal, and left-skewed. We see the opposite sort of curvature when the residuals are right-skewed:</p>
<p><img src="intro-bio-stats-book_files/figure-html/unnamed-chunk-170-1.png" width="384" style="display: block; margin: auto;" /></p>
<p>It is best to use a normal probability plot to assess normality assumptions in your own analyses. They work with every kind of model fitted by the <code>lm</code> function. What is more, they also work reasonably well when we only have a few residuals to play with.</p>
<p>That’s enough discussion of normal probability plots. Let’s move on to the constant variance evaluation.</p>
</div>
<div id="checking-the-constant-variance-assumption" class="section level3" number="20.3.4">
<h3><span class="header-section-number">20.3.4</span> Checking the constant variance assumption</h3>
<p>How do we evaluate the constant variance assumption of a linear regression? That is, how do we assess whether or not the variability of the residuals is constant or not? This assumption can be evaluated by producing something called a ‘scale-location plot.’ We construct this by plotting residuals against the fitted values, but instead of plotting raw residuals, we transform them first using the following ‘recipe’:</p>
<ol style="list-style-type: decimal">
<li><p>Standardise the residuals by dividing them by their standard deviation. Remember, this ensures the new residuals have a standard deviation of 1.</p></li>
<li><p>Find the absolute value of the residuals produced in step 1. If they are negative, make them positive; otherwise, leave them alone.</p></li>
<li><p>Take the square root of the residuals produced in step 2.</p></li>
</ol>
<p>These calculations are simple enough in R. We’ll demonstrate them using the partridge data set again:</p>
<div class="sourceCode" id="cb149"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb149-1"><a href="assumptions-and-diagnostics.html#cb149-1" aria-hidden="true" tabindex="-1"></a><span class="co"># extract the residuals</span></span>
<span id="cb149-2"><a href="assumptions-and-diagnostics.html#cb149-2" aria-hidden="true" tabindex="-1"></a>sqrt_abs_resids <span class="ot">&lt;-</span> <span class="fu">resid</span>(partridge_model)</span>
<span id="cb149-3"><a href="assumptions-and-diagnostics.html#cb149-3" aria-hidden="true" tabindex="-1"></a><span class="co"># step 1. standardise them</span></span>
<span id="cb149-4"><a href="assumptions-and-diagnostics.html#cb149-4" aria-hidden="true" tabindex="-1"></a>sqrt_abs_resids <span class="ot">&lt;-</span> sqrt_abs_resids <span class="sc">/</span> <span class="fu">sd</span>(sqrt_abs_resids)</span>
<span id="cb149-5"><a href="assumptions-and-diagnostics.html#cb149-5" aria-hidden="true" tabindex="-1"></a><span class="co"># step 2. find their absolute value</span></span>
<span id="cb149-6"><a href="assumptions-and-diagnostics.html#cb149-6" aria-hidden="true" tabindex="-1"></a>sqrt_abs_resids <span class="ot">&lt;-</span> <span class="fu">abs</span>(sqrt_abs_resids)</span>
<span id="cb149-7"><a href="assumptions-and-diagnostics.html#cb149-7" aria-hidden="true" tabindex="-1"></a><span class="co"># step 3. square root these</span></span>
<span id="cb149-8"><a href="assumptions-and-diagnostics.html#cb149-8" aria-hidden="true" tabindex="-1"></a>sqrt_abs_resids <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(sqrt_abs_resids)</span></code></pre></div>
<p>Now we use the <code>fitted</code> function to extract the fitted values from the model and place these in a data frame with the transformed residuals:</p>
<div class="sourceCode" id="cb150"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb150-1"><a href="assumptions-and-diagnostics.html#cb150-1" aria-hidden="true" tabindex="-1"></a>plt_data <span class="ot">&lt;-</span> </span>
<span id="cb150-2"><a href="assumptions-and-diagnostics.html#cb150-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">data.frame</span>(<span class="at">Fitted =</span> <span class="fu">fitted</span>(partridge_model), <span class="at">Resids =</span> sqrt_abs_resids)</span></code></pre></div>
<p>We called the data frame <code>plt_data</code>. Once we have made this data frame, we use <code>ggplot2</code> to plot the transformed residuals against the fitted values:</p>
<div class="sourceCode" id="cb151"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb151-1"><a href="assumptions-and-diagnostics.html#cb151-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(plt_data, <span class="fu">aes</span>(<span class="at">x =</span> Fitted, <span class="at">y =</span> Resids)) <span class="sc">+</span> </span>
<span id="cb151-2"><a href="assumptions-and-diagnostics.html#cb151-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span> </span>
<span id="cb151-3"><a href="assumptions-and-diagnostics.html#cb151-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">&quot;Fitted values&quot;</span>) <span class="sc">+</span> <span class="fu">ylab</span>(<span class="st">&quot;Square root of absolute residuals&quot;</span>)</span></code></pre></div>
<p><img src="intro-bio-stats-book_files/figure-html/unnamed-chunk-173-1.png" width="384" style="display: block; margin: auto;" /></p>
<p>This is a scale-location plot. Why is this useful? We want to assess whether or not the sizes of these new residuals increase or decrease as the fitted values get larger. If they do not—the relationship is essentially flat—then we can conclude that the variability in the residuals is constant. Otherwise, we have to conclude that the constant variance assumption is violated.</p>
<p>Although the pattern is not exactly clear cut, there seems to be a bit of an upward trend with respect to the fitted values in this example. This suggests that the variability (more formally, the ‘variance’) of the residuals increases with the fitted values. Larger partridge counts seem to be associated with more variability. This is a pervasive feature of count data.</p>
<div id="poor-model-fit-complicates-scale-location-plots" class="section level4 unnumbered infobox information">
<h4>Poor model fit complicates scale-location plots</h4>
<p>It is worth reflecting on the ambiguity in this pattern. It is suggestive, but it certainly isn’t as clear as the U-shape in the residuals vs fitted values plot used earlier. There is one potentially important reason for this ambiguity. The model we have used to describe the relationship between partridge counts and hedgerow density is not a very good model for these data. There is curvature in the relationship that we failed to take account of, and consequently, this lack of fit impacts the scale-location plot. When a model does not fit the data well, the scale-location plot does not only describe the variability in the residuals. It also reflects the lack of fit. The take-home message is that it is a good idea to fix a lack of fit problem before evaluating the constant variance assumption.</p>
</div>
<p>Non-constant variance can be a problem because it affects the validity of <em>p</em>-values associated with a model. You should aim to use scale-location plots to assess the constant variance assumption in your own analyses, but keep in mind that a scale-location plot may also reflect non-linearity.</p>
</div>
</div>
<div id="assumptions-of-one-way-anova" class="section level2" number="20.4">
<h2><span class="header-section-number">20.4</span> Assumptions of one-way ANOVA</h2>
<p>As regression and ANOVA are both types of linear model, it is unsurprising that the assumptions for these two types of models are very similar. However, there are some differences; for example, the linearity assumption does not make any sense with an ANOVA as the response variable is not numeric. Let’s step through each of the assumptions of a one-way ANOVA:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Independence.</strong> If the experimental units of the data are not independent, then the <em>p</em>-values generated by an <em>F</em>-test in an ANOVA will not be reliable. This one is important. Even mild non-independence can be a serious problem.</p></li>
<li><p><strong>Measurement scale.</strong> The response variable (<span class="math inline">\(y\)</span>) should be measured on an interval or ratio scale.</p></li>
<li><p><strong>Equal variance.</strong> The validity of <em>F</em>-tests associated with ANOVA depends on an assumption of equal variance in the treatment groups. If the data do not support this assumption, at least approximately, the <em>p</em>-values we generate may be unreliable.</p></li>
<li><p><strong>Normality.</strong> The validity of <em>F</em>-tests associated with ANOVA also depends on an assumption that the residuals are drawn from a normal distribution. ANOVA is reasonably robust to small departures from normality, but larger departures can start to matter. Unlike the <em>t</em>-test, having a large number of samples doesn’t make this assumption less important.</p></li>
</ol>
<p>Strictly speaking, assumptions 3 and 4 apply to the unobserved population from which the experimental samples are derived, i.e., the equal variance and normality assumptions are with respect to the variable of interest <em>in the population</em>. It’s important to keep this in mind when evaluating assumptions. For example, the estimated variances associated with different groups will always vary a bit due to sampling variation. That’s not necessarily a problem. It’s the big differences we need to worry about.</p>
<p>Notice that the term ‘regression diagnostic’ is a bit of a misnomer. A more accurate term might be ‘linear model diagnostic’ because regression diagnostics can be used with many different kinds of models. In fact, the diagnostic plots we have introduced above can be applied to any model fitted by the <code>lm</code> function. We’ll see this in the next chapter, where we’ll also introduce an easier way to make those key diagnostic plots.</p>

</div>
</div>
<div class="footnotes">
<hr />
<ol start="17">
<li id="fn17"><p>Even so-called ‘non-parametric’ models have underpinning assumptions; these are just not as restrictive as their parametric counterparts.<a href="assumptions-and-diagnostics.html#fnref17" class="footnote-back">↩︎</a></p></li>
<li id="fn18"><p>It sometimes makes sense to use a regression analysis when the predictor variable is an ordinal categorical variable. It depends what you want to do with the resulting model. However, some people disagree with this approach, so it’s best to avoid doing it unless you’re confident you can justify it.<a href="assumptions-and-diagnostics.html#fnref18" class="footnote-back">↩︎</a></p></li>
<li id="fn19"><p>It is the measurement error, not the sampling error, that matters. This means it is fine to use regression when the <span class="math inline">\(x\)</span> variable represent a sample from a population.<a href="assumptions-and-diagnostics.html#fnref19" class="footnote-back">↩︎</a></p></li>
<li id="fn20"><p>This is the situation we face with multiple regression. A multiple regression is a type of regression with more than one predictor variable—we don’t study them in this course, but they are often used in biology.<a href="assumptions-and-diagnostics.html#fnref20" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="anova-for-randomised-block-designs.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="regression-diagnostics-in-r.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["intro-bio-stats-book.pdf", "intro-bio-stats-book.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
